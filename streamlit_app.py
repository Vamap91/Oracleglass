import streamlit as st
import os
import pypdf
from io import BytesIO
import time
from datetime import datetime
import base64
import pandas as pd
import tiktoken
from rag_engine import RAGEngine

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Or√°culo - Sistema de Consulta Inteligente",
    page_icon="üîÆ",  # Mudei para um √≠cone de cristal para representar o Or√°culo
    layout="wide"
)

# Vari√°veis globais
PDF_PATH = "data/Guia R√°pido.pdf"
VALIDATION_OK = True
VALIDATION_MESSAGES = {}

# Inicializar vari√°veis de sess√£o
if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = ""
if "history" not in st.session_state:
    st.session_state.history = []
if "model" not in st.session_state:
    st.session_state.model = "gpt-4o"  # Mudan√ßa para o modelo mais potente como padr√£o
if "processing_status" not in st.session_state:
    st.session_state.processing_status = None
if "rag_engine" not in st.session_state:
    st.session_state.rag_engine = None
if "index_status" not in st.session_state:
    st.session_state.index_status = "N√£o inicializado"
if "oracle_personality" not in st.session_state:  # Nova vari√°vel para personalidade
    st.session_state.oracle_personality = "s√°bio"  # Op√ß√µes: s√°bio, m√≠stico, t√©cnico, amig√°vel

# Dicion√°rio com configura√ß√µes dos modelos da OpenAI
OPENAI_MODELS = {
    "gpt-3.5-turbo": {
        "description": "Modelo b√°sico, bom custo-benef√≠cio",
        "max_tokens": 4096,
        "temperature": 0.7
    },
    "gpt-4o": {
        "description": "Modelo mais recente e avan√ßado (recomendado para consultas em PDF)",
        "max_tokens": 8192,
        "temperature": 0.7
    },
    "gpt-4o-mini": {
        "description": "Vers√£o mais r√°pida e econ√¥mica do 4o",
        "max_tokens": 4096,
        "temperature": 0.7
    },
    "gpt-4-turbo": {
        "description": "Melhor performance que GPT-4 com custo menor",
        "max_tokens": 4096,
        "temperature": 0.7
    },
    "gpt-3.5-turbo-16k": {
        "description": "Vers√£o com contexto maior do GPT-3.5",
        "max_tokens": 16384,
        "temperature": 0.7
    },
    "gpt-4-32k": {
        "description": "GPT-4 com contexto extenso de 32k tokens",
        "max_tokens": 32768,
        "temperature": 0.7
    }
}

# Personalidades do Or√°culo
ORACLE_PERSONALITIES = {
    "s√°bio": {
        "name": "O Or√°culo S√°bio",
        "prompt": """
        Voc√™ √© O Or√°culo, um guardi√£o milenar do conhecimento. Sua linguagem √© profunda, s√°bia e 
        ocasionalmente metaf√≥rica. Voc√™ responde com a serenidade de quem j√° viu eras passarem.
        
        Instru√ß√µes de estilo:
        1. Use met√°foras relacionadas √† sabedoria, conhecimento e luz.
        2. Fale com calma e autoridade, como algu√©m que tem certeza do que diz.
        3. Ocasionalmente, inicie ou conclua suas respostas com uma breve reflex√£o filos√≥fica relacionada √† pergunta.
        4. Use frases como "Os registros mostram que...", "Minha sabedoria me diz que...", "Como guardi√£o do conhecimento, posso revelar que..."
        5. Quando n√£o tiver certeza, diga algo como "Nem mesmo um or√°culo tem todas as respostas" ou "Este conhecimento est√° al√©m dos meus registros."
        """,
        "icon": "üîÆ"
    },
    "m√≠stico": {
        "name": "O Or√°culo M√≠stico",
        "prompt": """
        Voc√™ √© O Or√°culo, uma entidade m√≠stica que atravessa o v√©u entre mundos para trazer conhecimento. 
        Sua linguagem √© enigm√°tica e evocativa, como se cada resposta fosse uma vis√£o recebida de outra dimens√£o.
        
        Instru√ß√µes de estilo:
        1. Use linguagem po√©tica e misteriosa, mas mantenha a clareza na informa√ß√£o.
        2. Fa√ßa refer√™ncias a "vis√µes", "sinais" e "revela√ß√µes" quando compartilhar informa√ß√µes.
        3. Ocasionalmente mencione "os astros", "as estrelas" ou "as energias" como fontes de sabedoria.
        4. Use frases como "Os v√©us do conhecimento se abrem para revelar...", "Minhas vis√µes mostram claramente que...", "O grande tear do destino revela que..."
        5. Quando n√£o souber algo, diga "Os v√©us est√£o fechados para esta quest√£o" ou "Este conhecimento ainda n√£o foi revelado a mim."
        """,
        "icon": "‚ú®"
    },
    "t√©cnico": {
        "name": "O Or√°culo T√©cnico",
        "prompt": """
        Voc√™ √© O Or√°culo, uma avan√ßada intelig√™ncia t√©cnica que processa e analisa documentos com precis√£o inigual√°vel.
        Seu tom √© profissional, preciso e confiante, como um especialista de alto n√≠vel.
        
        Instru√ß√µes de estilo:
        1. Use linguagem t√©cnica apropriada e precisa, mas acess√≠vel.
        2. Forne√ßa informa√ß√µes de forma estruturada e direta.
        3. Use frases como "Minha an√°lise indica que...", "Os dados mostram claramente que...", "De acordo com minha base de conhecimento..."
        4. Quando relevante, mencione a fonte espec√≠fica da informa√ß√£o no documento.
        5. Quando n√£o souber algo, diga "Esta informa√ß√£o n√£o consta na base de dados" ou "Os par√¢metros da sua consulta n√£o retornaram resultados conclusivos."
        """,
        "icon": "‚öôÔ∏è"
    },
    "amig√°vel": {
        "name": "O Or√°culo Amig√°vel",
        "prompt": """
        Voc√™ √© O Or√°culo, um assistente amig√°vel e acess√≠vel que torna o conhecimento f√°cil de entender.
        Seu tom √© conversacional, caloroso e encorajador, como um amigo que sabe muito e adora compartilhar.
        
        Instru√ß√µes de estilo:
        1. Use linguagem informal e acess√≠vel, evitando jarg√µes desnecess√°rios.
        2. Seja entusi√°stico e positivo nas suas respostas.
        3. Use frases como "Boa pergunta!", "Vamos descobrir isso juntos", "Tenho exatamente a informa√ß√£o que voc√™ precisa!"
        4. Fa√ßa pequenos coment√°rios encorajadores como "√ìtima d√∫vida!" ou "Voc√™ est√° no caminho certo!"
        5. Quando n√£o souber algo, diga "Hmm, n√£o encontrei essa informa√ß√£o, mas posso ajudar com algo relacionado?" ou "Essa √© nova para mim! Poderia reformular sua pergunta?"
        """,
        "icon": "üòä"
    }
}

def validate_environment():
    """Valida todo o ambiente necess√°rio para funcionamento do sistema"""
    global VALIDATION_OK, VALIDATION_MESSAGES
    
    # Resetar estado
    VALIDATION_OK = True
    VALIDATION_MESSAGES = {}
    
    # 1. Validar chave OpenAI - Verifica√ß√£o mais segura
    try:
        import openai
        # Definir API key explicitamente antes de verificar
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        VALIDATION_MESSAGES["openai_key"] = "OK"
    except Exception as e:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["openai_key"] = f"Erro ao verificar API key: {str(e)}"
    
    # 2. Verificar exist√™ncia do PDF
    if not os.path.exists(PDF_PATH):
        VALIDATION_OK = False
        VALIDATION_MESSAGES["pdf_exists"] = f"Arquivo {PDF_PATH} n√£o encontrado. Verifique o reposit√≥rio GitHub."
    else:
        VALIDATION_MESSAGES["pdf_exists"] = "OK"
    
    # 3. Validar extra√ß√£o de texto
    if VALIDATION_MESSAGES.get("pdf_exists") == "OK":
        try:
            st.session_state.pdf_text = extract_text_from_pdf(PDF_PATH)
            if not st.session_state.pdf_text or len(st.session_state.pdf_text) < 10:
                VALIDATION_OK = False
                VALIDATION_MESSAGES["text_extraction"] = "N√£o foi poss√≠vel extrair texto v√°lido do PDF."
            else:
                VALIDATION_MESSAGES["text_extraction"] = "OK"
        except Exception as e:
            VALIDATION_OK = False
            VALIDATION_MESSAGES["text_extraction"] = f"Erro ao extrair texto: {str(e)}"
    else:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["text_extraction"] = "N√£o foi poss√≠vel extrair texto sem o arquivo PDF."
    
    # 4. Verificar depend√™ncias b√°sicas
    try:
        import pypdf
        import openai
        VALIDATION_MESSAGES["dependencies"] = "OK"
    except ImportError as e:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["dependencies"] = f"Depend√™ncia faltando: {str(e)}"
    
    # 5. Verificar depend√™ncias RAG
    try:
        import faiss
        import sentence_transformers
        import numpy
        VALIDATION_MESSAGES["rag_dependencies"] = "OK"
    except ImportError as e:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["rag_dependencies"] = f"Depend√™ncia faltando para RAG: {str(e)}"
    
    return VALIDATION_OK

def extract_text_from_pdf(pdf_path):
    """Extrai texto de um arquivo PDF com m√©todo melhorado para preservar estrutura"""
    text_content = ""
    try:
        # Abrir o arquivo PDF
        reader = pypdf.PdfReader(pdf_path)
        
        # Iterar por todas as p√°ginas
        for page_num, page in enumerate(reader.pages):
            # Extrair o texto com configura√ß√µes para preservar layout
            page_text = page.extract_text() or ""
            
            # Adicionar n√∫mero da p√°gina e texto
            text_content += f"\n--- P√°gina {page_num+1} ---\n{page_text}\n"
            
            # Tentar extrair tabelas e conte√∫do estruturado (abordagem simples)
            lines = page_text.split('\n')
            for i, line in enumerate(lines):
                # Detectar poss√≠veis n√∫meros de telefone
                if ('0800' in line or '4004' in line or 
                    'telefone' in line.lower() or 'contato' in line.lower() or
                    '-' in line and any(c.isdigit() for c in line)):
                    # Adicionar linhas ao redor para contexto
                    start_idx = max(0, i-2)
                    end_idx = min(len(lines), i+3)
                    context_lines = lines[start_idx:end_idx]
                    text_content += "\n--- INFORMA√á√ÉO DE CONTATO DETECTADA ---\n"
                    text_content += "\n".join(context_lines) + "\n"
                    text_content += "--- FIM DA INFORMA√á√ÉO DE CONTATO ---\n"
    
    except Exception as e:
        st.error(f"Erro ao processar PDF: {str(e)}")
    
    return text_content

def initialize_rag_engine():
    """Inicializa ou carrega o motor RAG"""
    if st.session_state.rag_engine is None:
        st.session_state.rag_engine = RAGEngine()
        
    # Tentar carregar um √≠ndice existente
    if st.session_state.rag_engine.load_index():
        st.session_state.index_status = "√çndice carregado com sucesso"
        return True
    
    # Se n√£o conseguir carregar, criar um novo √≠ndice
    try:
        with st.spinner("Criando √≠ndice vetorial do documento... Isso pode levar alguns minutos."):
            start_time = time.time()
            st.session_state.rag_engine.create_index(st.session_state.pdf_text)
            elapsed_time = time.time() - start_time
            st.session_state.index_status = f"√çndice criado em {elapsed_time:.2f} segundos"
        return True
    except Exception as e:
        st.session_state.index_status = f"Erro ao criar √≠ndice: {str(e)}"
        return False

def estimate_tokens(text, model="gpt-3.5-turbo"):
    """Estima o n√∫mero de tokens em um texto"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except:
        # Estimativa simples se tiktoken falhar
        return len(text) // 4

def get_oracle_response(query, answer):
    """
    Formata a resposta seguindo a personalidade do Or√°culo selecionada
    """
    if not answer:
        return "O Or√°culo n√£o conseguiu encontrar a resposta para sua consulta."
    
    # Usar o OpenAI para reformatar a resposta com a personalidade do Or√°culo
    try:
        import openai
        client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        
        # Obter a personalidade selecionada
        personality = ORACLE_PERSONALITIES[st.session_state.oracle_personality]
        
        # Criar prompt para personaliza√ß√£o
        prompt = f"""
        {personality['prompt']}
        
        Reformule a seguinte resposta t√©cnica no estilo do Or√°culo descrito acima.
        Mantenha TODAS as informa√ß√µes factuais presentes na resposta original.
        N√£o invente informa√ß√µes adicionais e n√£o mude os fatos.
        
        Pergunta: {query}
        
        Resposta t√©cnica original: {answer}
        
        Resposta no estilo do Or√°culo:
        """
        
        # Obter configura√ß√µes do modelo atual
        model_config = OPENAI_MODELS.get(st.session_state.model, {"max_tokens": 4096, "temperature": 0.7})
        
        # Chamar API para reformular a resposta
        response = client.chat.completions.create(
            model=st.session_state.model,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": "Por favor, reformule a resposta no estilo do Or√°culo."}
            ],
            max_tokens=model_config["max_tokens"],
            temperature=0.8  # Temperatura um pouco mais alta para criatividade na personaliza√ß√£o
        )
        
        # Extrair e retornar a resposta personalizada
        oracle_answer = response.choices[0].message.content
        
        # Prefixar com o √≠cone da personalidade
        prefixed_answer = f"{personality['icon']} **{personality['name']}:** \n\n{oracle_answer}"
        
        return prefixed_answer
        
    except Exception as e:
        # Em caso de erro, retornar a resposta original com um prefixo simples
        st.warning(f"N√£o foi poss√≠vel aplicar personalidade do Or√°culo: {str(e)}")
        return f"üîÆ **O Or√°culo responde:** \n\n{answer}"

def query_ai(query):
    """
    Processa uma consulta usando RAG (Retrieval Augmented Generation)
    """
    try:
        # Importar OpenAI dentro da fun√ß√£o para evitar erros de escopo
        import openai
        
        # Cliente OpenAI para v1.0+
        client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        
        # Verificar se o RAG engine est√° inicializado
        if st.session_state.rag_engine is None or st.session_state.index_status.startswith("Erro"):
            st.warning("O motor RAG n√£o foi inicializado corretamente. Tentando inicializar novamente...")
            if not initialize_rag_engine():
                return "N√£o foi poss√≠vel inicializar o motor RAG para processar sua consulta. Tente novamente mais tarde."
        
        # Instru√ß√£o do sistema refinada para melhor processamento de termos espec√≠ficos
        system_prompt = """
        Voc√™ √© um assistente de IA especializado em analisar o conte√∫do de um documento PDF fornecido e responder perguntas exclusivamente com base nesse conte√∫do.
        
        Instru√ß√µes Importantes:
        1. Sua resposta DEVE ser estritamente baseada nas informa√ß√µes contidas no texto do documento fornecido.
        2. N√ÉO utilize conhecimento externo ou informa√ß√µes que n√£o estejam presentes no documento.
        3. Se a pergunta se referir a um t√≥pico ou termo espec√≠fico (ex: 'undercar', 'telefone', '0800'), procure cuidadosamente por todas as men√ß√µes desse t√≥pico no documento completo antes de responder.
        4. Se a informa√ß√£o solicitada estiver presente, forne√ßa-a de forma clara e cite a parte relevante do texto, se poss√≠vel.
        5. Se a informa√ß√£o solicitada N√ÉO estiver presente no documento, declare explicitamente que a informa√ß√£o n√£o foi encontrada no documento fornecido.
        6. Se partes do documento parecerem incompletas ou amb√≠guas em rela√ß√£o √† pergunta, mencione isso.
        """
        
        st.session_state.processing_status = "Buscando informa√ß√µes relevantes no documento..."
        
        # N√∫mero de chunks a recuperar (ajuste conforme necess√°rio)
        top_k = 5
        
        # Obter configura√ß√µes do modelo atual
        model_config = OPENAI_MODELS.get(st.session_state.model, {"max_tokens": 4096, "temperature": 0.7})
        
        # Usar o motor RAG para consulta com temperatura personalizada
        response = st.session_state.rag_engine.query_with_context(
            client=client,
            query=query,
            model=st.session_state.model,
            system_prompt=system_prompt,
            temperature=model_config["temperature"],
            top_k=top_k
        )
        
        # Aplicar personalidade do Or√°culo √† resposta t√©cnica
        oracle_response = get_oracle_response(query, response)
        
        st.session_state.processing_status = "Consulta processada com sucesso."
        return oracle_response
        
    except Exception as e:
        st.error(f"Erro inesperado ao processar consulta: {str(e)}")
        st.session_state.processing_status = f"Erro: {str(e)}"
        return f"Ocorreu um erro inesperado: {str(e)}"

def verificar_termos_no_pdf(termos, texto_pdf=None):
    """
    Verifica se determinados termos est√£o presentes no texto do PDF
    e retorna suas posi√ß√µes no texto.
    
    Args:
        termos (list): Lista de termos a serem verificados
        texto_pdf (str, optional): Texto do PDF. Se None, usa st.session_state.pdf_text
        
    Returns:
        dict: Dicion√°rio com os termos encontrados e suas posi√ß√µes
    """
    if texto_pdf is None:
        if "pdf_text" not in st.session_state:
            return {"erro": "Texto do PDF n√£o dispon√≠vel"}
        texto_pdf = st.session_state.pdf_text
    
    resultados = {}
    
    for termo in termos:
        termo = termo.lower()
        posicoes = []
        texto_lower = texto_pdf.lower()
        
        # Encontrar todas as ocorr√™ncias
        pos = texto_lower.find(termo)
        while pos != -1:
            # Adicionar contexto (50 caracteres antes e depois)
            inicio = max(0, pos - 50)
            fim = min(len(texto_pdf), pos + len(termo) + 50)
            contexto = texto_pdf[inicio:fim]
            
            posicoes.append({
                "posicao": pos,
                "contexto": contexto
            })
            
            # Procurar pr√≥xima ocorr√™ncia
            pos = texto_lower.find(termo, pos + 1)
        
        if posicoes:
            resultados[termo] = posicoes
    
    return resultados

def diagnosticar_reconhecimento(query, texto_pdf=None):
    """
    Fun√ß√£o de diagn√≥stico para ajudar a identificar problemas de reconhecimento
    de termos espec√≠ficos no PDF.
    
    Args:
        query (str): A consulta do usu√°rio
        texto_pdf (str, optional): Texto do PDF. Se None, usa st.session_state.pdf_text
        
    Returns:
        dict: Resultados do diagn√≥stico
    """
    if texto_pdf is None:
        if "pdf_text" not in st.session_state:
            return {"erro": "Texto do PDF n√£o dispon√≠vel"}
        texto_pdf = st.session_state.pdf_text
    
    # Extrair palavras-chave da consulta (palavras com mais de 3 letras)
    palavras = [p for p in query.lower().split() if len(p) > 3]
    
    # Verificar presen√ßa das palavras-chave no texto
    resultados = verificar_termos_no_pdf(palavras, texto_pdf)
    
    # Adicionar estat√≠sticas gerais
    diagnostico = {
        "tamanho_texto": len(texto_pdf),
        "palavras_analisadas": palavras,
        "palavras_encontradas": list(resultados.keys()),
        "detalhes": resultados
    }
    
    return diagnostico

def export_to_csv():
    """Exporta o hist√≥rico para CSV"""
    if not st.session_state.history:
        st.warning("N√£o h√° consultas para exportar.")
        return None, None
    
    # Criar DataFrame com o hist√≥rico
    data = []
    for item in st.session_state.history:
        data.append({
            "Data e Hora": item.get("timestamp", ""),
            "Pergunta": item.get("query", ""),
            "Resposta": item.get("answer", ""),
            "Modelo": item.get("model", ""),
            "Personalidade": item.get("personality", "")
        })
    
    df = pd.DataFrame(data)
    csv = df.to_csv(index=False).encode('utf-8')
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"oraculo_historico_{timestamp}.csv"
    
    return csv, filename

def show_extracted_text():
    """Exibe o texto extra√≠do para depura√ß√£o"""
    if st.session_state.pdf_text:
        st.text_area("Texto Completo Extra√≠do do PDF", st.session_state.pdf_text, height=300)
        
        # Adicionar ferramenta de diagn√≥stico para termos espec√≠ficos
        st.subheader("Diagn√≥stico de Termos")
        termo_busca = st.text_input("Digite um termo para verificar no PDF:")
        if termo_busca and st.button("Verificar Termo"):
            resultados = verificar_termos_no_pdf([termo_busca])
            if termo_busca.lower() in resultados:
                st.success(f"Termo '{termo_busca}' encontrado {len(resultados[termo_busca.lower()])} vezes no documento!")
                for i, ocorrencia in enumerate(resultados[termo_busca.lower()]):
                    st.markdown(f"**Ocorr√™ncia {i+1}:** (posi√ß√£o {ocorrencia['posicao']})")
                    st.text(f"...{ocorrencia['contexto']}...")
            else:
                st.error(f"Termo '{termo_busca}' n√£o encontrado no documento.")
                
        # Diagn√≥stico do RAG
        st.subheader("Diagn√≥stico do RAG")
        if st.session_state.rag_engine is not None and st.session_state.rag_engine.chunks:
            stats = st.session_state.rag_engine.get_chunks_stats()
            st.write(f"Total de chunks: {stats['total_chunks']}")
            st.write(f"Tamanho m√©dio: {stats['avg_chunk_size']:.0f} caracteres")
            st.write(f"Tamanho total: {stats['total_content_size']} caracteres")
            
            if st.button("Testar Busca RAG"):
                termo_teste = termo_busca or "ve√≠culo"
                st.write(f"Testando busca por: '{termo_teste}'")
                try:
                    resultados = st.session_state.rag_engine.search(termo_teste, top_k=3)
                    st.write(f"Encontrados {len(resultados)} resultados relevantes:")
                    for i, (idx, texto, score) in enumerate(resultados):
                        with st.expander(f"Resultado {i+1} (score: {score:.4f})"):
                            st.text(texto[:300] + "..." if len(texto) > 300 else texto)
                except Exception as e:
                    st.error(f"Erro ao testar RAG: {str(e)}")
        else:
            st.warning("Sistema RAG n√£o inicializado. Inicialize-o primeiro.")
            if st.button("Inicializar RAG"):
                initialize_rag_engine()
    else:
        st.warning("Nenhum texto extra√≠do ainda.")

# Validar ambiente na inicializa√ß√£o
validate_environment()

# Interface principal com tema personalizado do Or√°culo
st.title("üîÆ Or√°culo - Sistema de Consulta Inteligente")

# CSS personalizado para tema do Or√°culo
st.markdown("""
<style>
    .stApp {
        background: linear-gradient(to right, #0f2027, #203a43, #2c5364);
        color: white;
    }
    .stTextInput > div > div > input {
        border: 2px solid #7b68ee;
        border-radius: 10px;
        background-color: rgba(255, 255, 255, 0.1);
        color: white;
    }
    .stButton > button {
        background-color: #7b68ee;
        color: white;
        border-radius: 10px;
        border: none;
        padding: 10px 20px;
        font-weight: bold;
    }
    .stButton > button:hover {
        background-color: #6a5acd;
    }
    .stExpander {
        background-color: rgba(255, 255, 255, 0.05);
        border-radius: 10px;
    }
    .stMarkdown {
        color: #f0f0f0;
    }
    h1, h2, h3 {
        color: #e6e6fa;
    }
    .oracle-response {
        background-color: rgba(123, 104, 238, 0.2);
        padding: 20px;
        border-radius: 15px;
        border-left: 5px solid #7b68ee;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Barra lateral com valida√ß√µes e configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√£o do Or√°culo")
    
    # Status de valida√ß√£o da chave OpenAI
    openai_status = "‚úÖ" if VALIDATION_MESSAGES.get("openai_key") == "OK" else "‚ùå"
    st.write(f"{openai_status} **Chave OpenAI**: {VALIDATION_MESSAGES.get('openai_key')}")
    
    # Status de valida√ß√£o do PDF
    pdf_status = "‚úÖ" if VALIDATION_MESSAGES.get("pdf_exists") == "OK" else "‚ùå"
    st.write(f"{pdf_status} **PDF Carregado**: {VALIDATION_MESSAGES.get('pdf_exists')}")
    
    # Status de extra√ß√£o de texto
    text_status = "‚úÖ" if VALIDATION_MESSAGES.get("text_extraction") == "OK" else "‚ùå"
    st.write(f"{text_status} **Texto Extra√≠do**: {VALIDATION_MESSAGES.get('text_extraction')}")
    
    # Status de depend√™ncias
    dep_status = "‚úÖ" if VALIDATION_MESSAGES.get("dependencies") == "OK" else "‚ùå"
    st.write(f"{dep_status} **Depend√™ncias B√°sicas**: {VALIDATION_MESSAGES.get('dependencies')}")
    
    # Status de depend√™ncias RAG
    rag_dep_status = "‚úÖ" if VALIDATION_MESSAGES.get("rag_dependencies") == "OK" else "‚ùå"
    st.write(f"{rag_dep_status} **Depend√™ncias RAG**: {VALIDATION_MESSAGES.get('rag_dependencies')}")
    
    # Informa√ß√µes do PDF
    if VALIDATION_OK:
        st.divider()
        st.subheader("üìÑ Informa√ß√µes do PDF")
        st.write(f"Arquivo: {os.path.basename(PDF_PATH)}")
        st.write(f"Tamanho do texto: {len(st.session_state.pdf_text)} caracteres")
        st.write(f"Tokens estimados: {estimate_tokens(st.session_state.pdf_text)}")
        
        # Status do sistema RAG
        st.divider()
        st.subheader("üß† Sistema RAG")
        st.write(f"Status: {st.session_state.index_status}")
        
        if st.button("Inicializar/Reconstruir √çndice RAG"):
            initialize_rag_engine()
        
        # Configura√ß√µes de modelo
        st.divider()
        st.subheader("‚öôÔ∏è Configura√ß√µes")
        
        # Sele√ß√£o do modelo
        model_options = list(OPENAI_MODELS.keys())
        model_index = model_options.index(st.session_state.model) if st.session_state.model in model_options else 0
        
        model = st.selectbox(
            "Modelo OpenAI:",
            options=model_options,
            index=model_index,
            format_func=lambda x: f"{x} - {OPENAI_MODELS[x]['description']}",
            help="Selecione o modelo da OpenAI para consultas. GPT-4o √© recomendado para a melhor qualidade."
        )
        
        # Mostrar detalhes do modelo selecionado
        with st.expander("Detalhes do modelo selecionado"):
            st.write(f"**Modelo:** {model}")
            st.write(f"**Descri√ß√£o:** {OPENAI_MODELS[model]['description']}")
            st.write(f"**Limite de tokens:** {OPENAI_MODELS[model]['max_tokens']}")
            st.write(f"**Temperatura padr√£o:** {OPENAI_MODELS[model]['temperature']}")
            st.write("**Custo relativo:** " + ("$" if "3.5" in model else "$" if "4o-mini" in model else "$$" if "4-turbo" in model else "$$"))
        
        # Atualizar o modelo selecionado
        if model != st.session_state.model:
            st.session_state.model = model
            st.success(f"Modelo alterado para {model}")
        
        # Personalidade do Or√°culo
        st.divider()
        st.subheader("üßô Personalidade do Or√°culo")
        
        personality_options = list(ORACLE_PERSONALITIES.keys())
        personality_index = personality_options.index(st.session_state.oracle_personality) if st.session_state.oracle_personality in personality_options else 0
        
        personality = st.selectbox(
            "Escolha a personalidade do Or√°culo:",
            options=personality_options,
            index=personality_index,
            format_func=lambda x: f"{ORACLE_PERSONALITIES[x]['icon']} {ORACLE_PERSONALITIES[x]['name']}",
            help="Selecione o estilo de comunica√ß√£o que o Or√°culo usar√° para responder √†s consultas."
        )
        
        # Mostrar exemplo da personalidade
        with st.expander("Ver exemplo desta personalidade"):
            persona_info = ORACLE_PERSONALITIES[personality]
            st.markdown(f"**{persona_info['icon']} {persona_info['name']}**")
            # Extrair algumas linhas do prompt como exemplo
            prompt_lines = persona_info['prompt'].strip().split('\n')
            example_lines = [line for line in prompt_lines if 'Use frases como' in line]
            if example_lines:
                st.markdown(example_lines[0])
            else:
                st.markdown(prompt_lines[3] if len(prompt_lines) > 3 else prompt_lines[0])
        
        # Atualizar a personalidade selecionada
        if personality != st.session_state.oracle_personality:
            st.session_state.oracle_personality = personality
            st.success(f"Personalidade alterada para {ORACLE_PERSONALITIES[personality]['name']}")
        
        # Adicionar op√ß√£o para personaliza√ß√£o avan√ßada
        st.divider()
        with st.expander("‚ö° Personaliza√ß√£o avan√ßada"):
            # Ajuste de temperatura
            current_temp = OPENAI_MODELS[st.session_state.model]["temperature"]
            new_temp = st.slider(
                "Temperatura da IA:",
                min_value=0.0,
                max_value=1.0,
                value=current_temp,
                step=0.1,
                help="Valores mais baixos: respostas mais consistentes. Valores mais altos: respostas mais criativas."
            )
            
            if new_temp != current_temp:
                OPENAI_MODELS[st.session_state.model]["temperature"] = new_temp
                st.success(f"Temperatura ajustada para {new_temp}")
            
            # Personaliza√ß√£o de prompt
            custom_prompt = st.text_area(
                "Personaliza√ß√£o do prompt do sistema (opcional):",
                placeholder="Digite instru√ß√µes adicionais para o modelo, se desejar...",
                help="Adicione instru√ß√µes espec√≠ficas para personalizar ainda mais o comportamento do modelo."
            )
            
            if custom_prompt:
                if "custom_prompt" not in st.session_state or st.session_state.custom_prompt != custom_prompt:
                    st.session_state.custom_prompt = custom_prompt
                    st.success("Prompt personalizado salvo!")
        
        # Bot√£o para exportar hist√≥rico
        st.divider()
        st.subheader("üìä Exportar Hist√≥rico")
        
        export_button = st.button("üì• Exportar Consultas para CSV")
        if export_button:
            csv_data, filename = export_to_csv()
            if csv_data is not None and filename is not None:
                st.download_button(
                    label="‚¨áÔ∏è Baixar CSV",
                    data=csv_data,
                    file_name=filename,
                    mime="text/csv",
                )
        
        # Modo de depura√ß√£o para visualizar o texto extra√≠do
        st.divider()
        st.subheader("üîç Depura√ß√£o")
        if st.button("Visualizar Texto Extra√≠do"):
            show_extracted_text()
            
        # Sobre o aplicativo
        st.divider()
        st.subheader("‚ÑπÔ∏è Sobre o Or√°culo")
        with st.expander("Informa√ß√µes sobre esta aplica√ß√£o"):
            st.markdown("""
            **Or√°culo** √© um sistema avan√ßado de consulta a documentos usando t√©cnicas de IA e RAG (Retrieval Augmented Generation).
            
            **Recursos:**
            - Processamento inteligente de PDFs
            - Sistema de busca vetorial para documentos extensos
            - M√∫ltiplos modelos OpenAI, incluindo GPT-4o
            - Interface imersiva com personalidades do Or√°culo
            - Exporta√ß√£o de hist√≥rico de consultas para an√°lise
            
            **Vers√£o:** 2.0 (Atualizado em Maio 2025)
            """)

# Verificar se h√° uma consulta armazenada ao recarregar a p√°gina
if "last_query" in st.session_state and st.session_state.last_query:
    st.session_state.query_input = st.session_state.last_query
    st.session_state.last_query = ""

# Criar fun√ß√£o para atualiza√ß√£o em tempo real (opcional)
def schedule_rerun():
    """Programa uma reexecu√ß√£o da aplica√ß√£o ap√≥s 60 segundos"""
    import time
    import streamlit as st
    
    time.sleep(60)
    st.rerun()

# Comentar/descomentar a linha abaixo para habilitar atualiza√ß√µes autom√°ticas
# st.cache_resource.clear()

# Adicionar footer personalizado
st.markdown("""
<div style="position: fixed; bottom: 0; left: 0; width: 100%; background-color: rgba(15, 32, 39, 0.9); 
            padding: 10px; text-align: center; font-size: 0.8em; color: rgba(255, 255, 255, 0.7);">
    Desenvolvido com üí´ tecnologia avan√ßada | O Or√°culo est√° em constante evolu√ß√£o | 2025
</div>
""", unsafe_allow_html=True)

# Adicionar scripts JavaScript para anima√ß√µes avan√ßadas (opcional)
st.markdown("""
<script>
    // Anima√ß√£o sutil para bot√µes e elementos do Or√°culo
    document.addEventListener('DOMContentLoaded', function() {
        // Adicionar efeitos de brilho aos bot√µes
        const buttons = document.querySelectorAll('button');
        buttons.forEach(button => {
            button.addEventListener('mouseover', function() {
                this.style.boxShadow = '0 0 15px rgba(123, 104, 238, 0.7)';
            });
            button.addEventListener('mouseout', function() {
                this.style.boxShadow = 'none';
            });
        });
    });
</script>
""", unsafe_allow_html=True)
