import streamlit as st
import os
import pypdf
from io import BytesIO
import time
from datetime import datetime
import base64
import pandas as pd

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Or√°culo - Sistema de Consulta Inteligente",
    page_icon="üöó",
    layout="wide"
)

# Vari√°veis globais
PDF_PATH = "data/Guia R√°pido.pdf"
VALIDATION_OK = True
VALIDATION_MESSAGES = {}

# Inicializar vari√°veis de sess√£o
if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = ""
if "history" not in st.session_state:
    st.session_state.history = []
if "model" not in st.session_state:
    st.session_state.model = "gpt-3.5-turbo"  # Modelo padr√£o mais econ√¥mico

def validate_environment():
    """Valida todo o ambiente necess√°rio para funcionamento do sistema"""
    global VALIDATION_OK, VALIDATION_MESSAGES
    
    # Resetar estado
    VALIDATION_OK = True
    VALIDATION_MESSAGES = {}
    
    # 1. Validar chave OpenAI - Verifica√ß√£o mais segura
    try:
        import openai
        # Definir API key explicitamente antes de verificar
        openai.api_key = st.secrets["OPENAI_API_KEY"]
        VALIDATION_MESSAGES["openai_key"] = "OK"
    except Exception as e:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["openai_key"] = f"Erro ao verificar API key: {str(e)}"
    
    # 2. Verificar exist√™ncia do PDF
    if not os.path.exists(PDF_PATH):
        VALIDATION_OK = False
        VALIDATION_MESSAGES["pdf_exists"] = f"Arquivo {PDF_PATH} n√£o encontrado. Verifique o reposit√≥rio GitHub."
    else:
        VALIDATION_MESSAGES["pdf_exists"] = "OK"
    
    # 3. Validar extra√ß√£o de texto
    if VALIDATION_MESSAGES.get("pdf_exists") == "OK":
        try:
            st.session_state.pdf_text = extract_text_from_pdf(PDF_PATH)
            if not st.session_state.pdf_text or len(st.session_state.pdf_text) < 10:
                VALIDATION_OK = False
                VALIDATION_MESSAGES["text_extraction"] = "N√£o foi poss√≠vel extrair texto v√°lido do PDF."
            else:
                VALIDATION_MESSAGES["text_extraction"] = "OK"
        except Exception as e:
            VALIDATION_OK = False
            VALIDATION_MESSAGES["text_extraction"] = f"Erro ao extrair texto: {str(e)}"
    else:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["text_extraction"] = "N√£o foi poss√≠vel extrair texto sem o arquivo PDF."
    
    # 4. Verificar depend√™ncias
    try:
        import pypdf
        import openai
        VALIDATION_MESSAGES["dependencies"] = "OK"
    except ImportError as e:
        VALIDATION_OK = False
        VALIDATION_MESSAGES["dependencies"] = f"Depend√™ncia faltando: {str(e)}"
    
    return VALIDATION_OK

def extract_text_from_pdf(pdf_path):
    """Extrai texto de um arquivo PDF com m√©todo melhorado para preservar estrutura"""
    text_content = ""
    try:
        # Abrir o arquivo PDF
        reader = pypdf.PdfReader(pdf_path)
        
        # Iterar por todas as p√°ginas
        for page_num, page in enumerate(reader.pages):
            # Extrair o texto com configura√ß√µes para preservar layout
            page_text = page.extract_text() or ""
            
            # Adicionar n√∫mero da p√°gina e texto
            text_content += f"\n--- P√°gina {page_num+1} ---\n{page_text}\n"
            
            # Tentar extrair tabelas e conte√∫do estruturado (abordagem simples)
            lines = page_text.split('\n')
            for i, line in enumerate(lines):
                # Detectar poss√≠veis n√∫meros de telefone
                if ('0800' in line or '4004' in line or 
                    'telefone' in line.lower() or 'contato' in line.lower() or
                    '-' in line and any(c.isdigit() for c in line)):
                    # Adicionar linhas ao redor para contexto
                    start_idx = max(0, i-2)
                    end_idx = min(len(lines), i+3)
                    context_lines = lines[start_idx:end_idx]
                    text_content += "\n--- INFORMA√á√ÉO DE CONTATO DETECTADA ---\n"
                    text_content += "\n".join(context_lines) + "\n"
                    text_content += "--- FIM DA INFORMA√á√ÉO DE CONTATO ---\n"
    
    except Exception as e:
        st.error(f"Erro ao processar PDF: {str(e)}")
    
    return text_content

def query_ai(query):
    """Processa uma consulta usando a API da OpenAI - Compat√≠vel com vers√£o 1.0+
       Modificado para enviar o contexto completo do PDF.
    """
    try:
        # Importar OpenAI dentro da fun√ß√£o para evitar erros de escopo
        import openai
        
        # Cliente OpenAI para v1.0+
        client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        
        # *** MODIFICA√á√ÉO PRINCIPAL: Remover a limita√ß√£o de 'max_length' ***
        # O contexto agora ser√° o texto completo extra√≠do do PDF.
        context = st.session_state.pdf_text 
        
        # Instru√ß√£o do sistema refinada para melhor processamento de termos espec√≠ficos
        system_prompt = """
        Voc√™ √© um assistente de IA especializado em analisar o conte√∫do de um documento PDF fornecido e responder perguntas exclusivamente com base nesse conte√∫do.
        
        Instru√ß√µes Importantes:
        1. Sua resposta DEVE ser estritamente baseada nas informa√ß√µes contidas no texto do documento fornecido.
        2. N√ÉO utilize conhecimento externo ou informa√ß√µes que n√£o estejam presentes no documento.
        3. Se a pergunta se referir a um t√≥pico ou termo espec√≠fico (ex: 'undercar', 'telefone', '0800'), procure cuidadosamente por todas as men√ß√µes desse t√≥pico no documento completo antes de responder.
        4. Se a informa√ß√£o solicitada estiver presente, forne√ßa-a de forma clara e cite a parte relevante do texto, se poss√≠vel.
        5. Se a informa√ß√£o solicitada N√ÉO estiver presente no documento, declare explicitamente que a informa√ß√£o n√£o foi encontrada no documento fornecido.
        6. Se partes do documento parecerem incompletas ou amb√≠guas em rela√ß√£o √† pergunta, mencione isso.
        """
        
        # Chamada da API atualizada para v1.0+
        response = client.chat.completions.create(
            model=st.session_state.model, # Usa o modelo selecionado na interface
            messages=[
                {"role": "system", "content": system_prompt},
                # Envia o contexto completo
                {"role": "user", "content": f"Com base EXCLUSIVAMENTE no seguinte documento, responda √† pergunta: '{query}'\n\nConte√∫do Completo do Documento:\n{context}"}
            ],
            temperature=0.2,  # Manter baixo para respostas factuais baseadas no texto
            max_tokens=1000 # Aumentar ligeiramente caso a resposta precise ser mais longa
        )
        
        return response.choices[0].message.content
    
    except openai.BadRequestError as e:
        # Capturar erro espec√≠fico de contexto muito longo
        if "context_length_exceeded" in str(e):
            st.error(f"Erro: O documento √© muito longo para o modelo selecionado ('{st.session_state.model}'). Tente selecionar um modelo com maior capacidade de contexto (ex: gpt-4-turbo, gpt-4o) ou reduza o tamanho do PDF.")
            return "Erro: O documento excede a capacidade de processamento do modelo selecionado."
        else:
            st.error(f"Erro na API OpenAI: {str(e)}")
            return f"Ocorreu um erro ao processar sua consulta com a OpenAI: {str(e)}"
            
    except Exception as e:
        st.error(f"Erro inesperado ao processar consulta: {str(e)}")
        return f"Ocorreu um erro inesperado: {str(e)}"

# Fun√ß√£o auxiliar para verificar a presen√ßa de termos espec√≠ficos no texto extra√≠do
def verificar_termos_no_pdf(termos, texto_pdf=None):
    """
    Verifica se determinados termos est√£o presentes no texto do PDF
    e retorna suas posi√ß√µes no texto.
    
    Args:
        termos (list): Lista de termos a serem verificados
        texto_pdf (str, optional): Texto do PDF. Se None, usa st.session_state.pdf_text
        
    Returns:
        dict: Dicion√°rio com os termos encontrados e suas posi√ß√µes
    """
    if texto_pdf is None:
        if "pdf_text" not in st.session_state:
            return {"erro": "Texto do PDF n√£o dispon√≠vel"}
        texto_pdf = st.session_state.pdf_text
    
    resultados = {}
    
    for termo in termos:
        termo = termo.lower()
        posicoes = []
        texto_lower = texto_pdf.lower()
        
        # Encontrar todas as ocorr√™ncias
        pos = texto_lower.find(termo)
        while pos != -1:
            # Adicionar contexto (50 caracteres antes e depois)
            inicio = max(0, pos - 50)
            fim = min(len(texto_pdf), pos + len(termo) + 50)
            contexto = texto_pdf[inicio:fim]
            
            posicoes.append({
                "posicao": pos,
                "contexto": contexto
            })
            
            # Procurar pr√≥xima ocorr√™ncia
            pos = texto_lower.find(termo, pos + 1)
        
        if posicoes:
            resultados[termo] = posicoes
    
    return resultados

# Fun√ß√£o para diagn√≥stico de problemas de reconhecimento
def diagnosticar_reconhecimento(query, texto_pdf=None):
    """
    Fun√ß√£o de diagn√≥stico para ajudar a identificar problemas de reconhecimento
    de termos espec√≠ficos no PDF.
    
    Args:
        query (str): A consulta do usu√°rio
        texto_pdf (str, optional): Texto do PDF. Se None, usa st.session_state.pdf_text
        
    Returns:
        dict: Resultados do diagn√≥stico
    """
    if texto_pdf is None:
        if "pdf_text" not in st.session_state:
            return {"erro": "Texto do PDF n√£o dispon√≠vel"}
        texto_pdf = st.session_state.pdf_text
    
    # Extrair palavras-chave da consulta (palavras com mais de 3 letras)
    palavras = [p for p in query.lower().split() if len(p) > 3]
    
    # Verificar presen√ßa das palavras-chave no texto
    resultados = verificar_termos_no_pdf(palavras, texto_pdf)
    
    # Adicionar estat√≠sticas gerais
    diagnostico = {
        "tamanho_texto": len(texto_pdf),
        "palavras_analisadas": palavras,
        "palavras_encontradas": list(resultados.keys()),
        "detalhes": resultados
    }
    
    return diagnostico

def export_to_csv():
    """Exporta o hist√≥rico para CSV"""
    if not st.session_state.history:
        st.warning("N√£o h√° consultas para exportar.")
        return None, None
    
    # Criar DataFrame com o hist√≥rico
    data = []
    for item in st.session_state.history:
        data.append({
            "Data e Hora": item.get("timestamp", ""),
            "Pergunta": item.get("query", ""),
            "Resposta": item.get("answer", ""),
            "Modelo": item.get("model", "")
        })
    
    df = pd.DataFrame(data)
    csv = df.to_csv(index=False).encode('utf-8')
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"oraculo_historico_{timestamp}.csv"
    
    return csv, filename

# Visualizar texto extra√≠do no modo de depura√ß√£o
def show_extracted_text():
    """Exibe o texto extra√≠do para depura√ß√£o"""
    if st.session_state.pdf_text:
        st.text_area("Texto Completo Extra√≠do do PDF", st.session_state.pdf_text, height=300)
        
        # Adicionar ferramenta de diagn√≥stico para termos espec√≠ficos
        st.subheader("Diagn√≥stico de Termos")
        termo_busca = st.text_input("Digite um termo para verificar no PDF:")
        if termo_busca and st.button("Verificar Termo"):
            resultados = verificar_termos_no_pdf([termo_busca])
            if termo_busca.lower() in resultados:
                st.success(f"Termo '{termo_busca}' encontrado {len(resultados[termo_busca.lower()])} vezes no documento!")
                for i, ocorrencia in enumerate(resultados[termo_busca.lower()]):
                    st.markdown(f"**Ocorr√™ncia {i+1}:** (posi√ß√£o {ocorrencia['posicao']})")
                    st.text(f"...{ocorrencia['contexto']}...")
            else:
                st.error(f"Termo '{termo_busca}' n√£o encontrado no documento.")
    else:
        st.warning("Nenhum texto extra√≠do ainda.")

# Validar ambiente na inicializa√ß√£o
validate_environment()

# Interface principal
st.title("üöó Or√°culo - Sistema de Consulta Inteligente")

# Barra lateral com valida√ß√µes e configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Valida√ß√£o do Sistema")
    
    # Status de valida√ß√£o da chave OpenAI
    openai_status = "‚úÖ" if VALIDATION_MESSAGES.get("openai_key") == "OK" else "‚ùå"
    st.write(f"{openai_status} **Chave OpenAI**: {VALIDATION_MESSAGES.get('openai_key')}")
    
    # Status de valida√ß√£o do PDF
    pdf_status = "‚úÖ" if VALIDATION_MESSAGES.get("pdf_exists") == "OK" else "‚ùå"
    st.write(f"{pdf_status} **PDF Carregado**: {VALIDATION_MESSAGES.get('pdf_exists')}")
    
    # Status de extra√ß√£o de texto
    text_status = "‚úÖ" if VALIDATION_MESSAGES.get("text_extraction") == "OK" else "‚ùå"
    st.write(f"{text_status} **Texto Extra√≠do**: {VALIDATION_MESSAGES.get('text_extraction')}")
    
    # Status de depend√™ncias
    dep_status = "‚úÖ" if VALIDATION_MESSAGES.get("dependencies") == "OK" else "‚ùå"
    st.write(f"{dep_status} **Depend√™ncias**: {VALIDATION_MESSAGES.get('dependencies')}")
    
    # Informa√ß√µes do PDF
    if VALIDATION_OK:
        st.divider()
        st.subheader("üìÑ Informa√ß√µes do PDF")
        st.write(f"Arquivo: {os.path.basename(PDF_PATH)}")
        st.write(f"Tamanho do texto: {len(st.session_state.pdf_text)} caracteres")
        
        # Configura√ß√µes de modelo - ATUALIZADO COM MAIS OP√á√ïES
        st.divider()
        st.subheader("‚öôÔ∏è Configura√ß√µes")
        
        model = st.selectbox(
            "Modelo OpenAI:",
            options=[
                "gpt-3.5-turbo",      # Modelo b√°sico, bom custo-benef√≠cio
                "gpt-4",              # Melhor qualidade, mais caro
                "gpt-4-turbo",        # Melhor performance que GPT-4 com custo menor
                "gpt-4o",             # GPT-4 Omni - modelo mais recente
                "gpt-3.5-turbo-16k",  # Vers√£o com contexto maior
                "gpt-4-32k",          # GPT-4 com contexto de 32k tokens
            ],
            index=0,  # Default para o modelo mais econ√¥mico
            help="Selecione o modelo da OpenAI. GPT-3.5 √© mais r√°pido e econ√¥mico, GPT-4 √© mais preciso, modelos com n√∫mero maior suportam mais contexto."
        )
        
        # Atualizar o modelo selecionado
        if model != st.session_state.model:
            st.session_state.model = model
            st.info(f"Modelo alterado para {model}")
        
        # Bot√£o para exportar hist√≥rico
        st.divider()
        st.subheader("üìä Exportar Hist√≥rico")
        
        export_button = st.button("üì• Exportar Consultas para CSV")
        if export_button:
            csv_data, filename = export_to_csv()
            if csv_data is not None and filename is not None:
                st.download_button(
                    label="‚¨áÔ∏è Baixar CSV",
                    data=csv_data,
                    file_name=filename,
                    mime="text/csv",
                )
        
        # Modo de depura√ß√£o para visualizar o texto extra√≠do
        st.divider()
        st.subheader("üîç Depura√ß√£o")
        if st.button("Visualizar Texto Extra√≠do"):
            show_extracted_text()

# Conte√∫do principal - Sempre exibir, independente da valida√ß√£o
st.write("Digite sua pergunta sobre ve√≠culos e clique em 'Consultar'.")

# Campo de consulta
query = st.text_input("‚ùì Sua pergunta:", key="query_input")

# Bot√£o de consulta
consult_button = st.button("üîç Consultar", key="query_button", disabled=not VALIDATION_OK)
if consult_button and query:
    with st.spinner("Processando consulta..."):
        answer = query_ai(query)
        
        if answer:
            st.divider()
            st.subheader("üìù Resposta:")
            st.markdown(answer)
            
            # Adicionar ao hist√≥rico com timestamp
            st.session_state.history.append({
                "query": query,
                "answer": answer,
                "model": st.session_state.model,
                "timestamp": datetime.now().strftime("%d/%m/%Y %H:%M:%S")
            })

# Hist√≥rico de consultas - sempre mostrar se houver itens
if st.session_state.history:
    st.divider()
    st.subheader("üìã Hist√≥rico de Consultas")
    
    for i, item in enumerate(reversed(st.session_state.history)):
        question = item.get("query", "")
        with st.expander(f"Pergunta ({i+1}): {question}"):
            st.markdown(f"**Data e Hora:** {item.get('timestamp', '')}")
            st.markdown(f"**Modelo:** {item.get('model', '')}")
            st.markdown("**Resposta:**")
            st.markdown(item.get('answer', ''))
